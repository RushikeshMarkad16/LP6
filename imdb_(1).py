# -*- coding: utf-8 -*-
"""IMDB (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MXsnwu1nAhWGLwvGVqVQNhCQCQJ8JBNJ

#### Problem Statement: 
    Classification using Deep neural network 
        Binary classification using Deep Neural Networks Example: Classify movie reviews into positive" reviews and "negative" reviews, just based on the text content of the reviews. Use IMDB dataset
                                                 
IMDB Dataset: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/download?datasetVersionNumber=1

### Importing libraries
"""

# Import required libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

"""## Binary Classification

### Importing libraries
"""

import re
import nltk
from tqdm.auto import tqdm
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score

# Load the dataset
data = pd.read_csv("IMDB Dataset.csv")

data.head()

data.tail()

data.isna().sum()

data.shape

data = data.iloc[:10000, :]
data.shape

# Create a bar plot of the class distribution
class_counts = data['sentiment'].value_counts()
class_counts.plot(kind='bar')
plt.title('Class Distribution of Sentiments')
plt.xlabel('Sentiments')
plt.ylabel('Number of Reviews')
plt.show()

# Clean the data
def clean_text(text):
    # Remove HTML tags
    text = re.sub('<.*?>', '', text)
    # Remove non-alphabetic characters and convert to lowercase
    text = re.sub('[^a-zA-Z]', ' ', text).lower()
    # Tokenize the text
    words = nltk.word_tokenize(text)
    # Remove stopwords
    words = [w for w in words if w not in stopwords.words('english')]
    # Stem the words
    stemmer = PorterStemmer()
    words = [stemmer.stem(w) for w in words]
    # Join the words back into a string
    text = ' '.join(words)
    return text

# tqdm.pandas()
# data['cleaned_text'] = data['review'].progress_apply(clean_text)

# create a mapping dictionary to replace "positive" with 1 and "negative" with 0
mapping = {'positive': 1, 'negative': 0}

# use the map() function to apply the mapping dictionary to the "sentiment" column
data['sentiment'] = data['sentiment'].map(mapping)

# Create the Bag of Words model
cv = CountVectorizer(max_features=5000)
X = cv.fit_transform(data['review']).toarray()
#X = cv.fit_transform(data['cleaned_text']).toarray()
y = data['sentiment']

X

X.shape

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### Neural Network Model"""

# Import libraries
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense

# Define the model architecture
model = Sequential()
model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)

# evaluate the classifier on the test set
y_pred = model.predict(X_test)

y_pred = [0 if i < 0.5 else 1 for i in y_pred]
y_pred

"""### Evaluating Performance"""

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test loss: {loss:.3}')
print(f'Test accuracy: {accuracy:.3%}')

acc = accuracy_score(y_test, y_pred)
print("Accuracy:", acc)

"""### Confusion Matrix"""

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='.3f')

